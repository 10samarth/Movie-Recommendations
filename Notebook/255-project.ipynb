{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1828f64",
   "metadata": {},
   "source": [
    "# Movie-Recommendations\n",
    "\n",
    "Movie Recommendations with Movielens Dataset\n",
    "\n",
    "Almost everyone today uses technology to stream movies and television shows. While figuring out what to stream next can be daunting, recommendations are often made based on a viewerâ€™s history and preferences. This is done through machine learning and can be a fun and easy project for beginners to take on. New programmers can practice by coding in either Python or R languages and with data from the Movielens Dataset. Generated by more than 6,000 users, Movielens currently includes more than 1 million movie ratings of 3,900 films.\n",
    "\n",
    "Dataset link: [https://grouplens.org/datasets/movielens/1m/](https://grouplens.org/datasets/movielens/1m/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5d21ff",
   "metadata": {},
   "source": [
    "A **recommendation system** predicts the rating or the preference a user might give to an item. It is an algorithm that suggests relevant things to users. Thus, Recommender systems aim to present relevant items to users based on various factors. Recommender systems are widely used in products like in the case of Netflix, it recommends which movie to watch, in case of e-commerce, which product to buy, or in the case of kindle, which book to read, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a38476d",
   "metadata": {},
   "source": [
    "**Word embeddings** represent words that allow words with similar meanings to have an equal representation. Stemming uses the word's stem, while lemmatization uses the context in which the term is used.\n",
    "\n",
    "For grammatical reasons, sentences use different word forms, such as organize, organizes, and organizing. Additionally, there are families of derivationally related words with similar meanings, such as democracy, democratic, and democratization. Both stemming and lemmatization aim to reduce inflectional and derivationally related phrases to a common form.\n",
    "\n",
    "example:\n",
    "\n",
    "am, are, is => be\n",
    "\n",
    "car, cars, car's, cars' => car\n",
    "\n",
    "**Stemming** algorithms work by trimming off the end of the word, taking into account a list of common prefixes and suffixes found in a word.\n",
    "\n",
    "**Lemmatization** considers the morphological examination of the words. It is essential to have dictionaries that the algorithm can refers through to link the form to its lemma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d11802",
   "metadata": {},
   "source": [
    "**TF-IDF**, known as the term frequency-inverse document frequency, is a statistical measurement that estimates how a word is relevant to a document in a group of documents. This is achieved by multiplying two metrics, the number of times a word appears in a document and the inverse document frequency of the word across a set of documents. To simplify it is a text vectorizer that transforms the text into a usable vector. It combines two concepts, Term Frequency (TF) and Document Frequency (DF)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbab2bc5",
   "metadata": {},
   "source": [
    "\n",
    "**Content-based filtering system:** Content-Based recommender system predicts the features or behavior of given the item's attributes to which the user will react positively. During recommendation, the similarity metrics are computed from the item's feature vectors and the user's preferred feature vectors from previous data. Then, the top few are recommended. It does not require other users' data during recommendation.\n",
    "\n",
    "  \n",
    "\n",
    "**Collaborative filtering System:** Collaborative does not require the features of the items. Every user and entity is described using a feature vector or embedding. It builds an embedding for both users and items. It takes into consideration other users' reactions while recommending a particular user. It records which items a particular user likes and the items that the users with behavior and likings of other users, to recommend things to that user. It collects user feedback on different items and uses them for recommendations.\n",
    "\n",
    "\n",
    "Differences between Collaborative Filtering and Content-Based Filtering :\n",
    "\n",
    "-   The Content-based method requires information about the item's features instead of using the user's liking and feedback. It can be any attributes of items such as plot, year, genre, or text that is extracted by applying NLP. \n",
    "- Collaborative Filtering doesn't need anything else except the user's preference on items to recommend. As it is based on historical data, the assumption made is that the users who have agreed in the past will also tend to agree in the future.\n",
    "-   Domain knowledge is not required in the case of Collaborative Filtering as the embeddings are automatically learned. \n",
    "- In the case of a Content-based approach, the feature representation of the items is hand-engineered to an extent, this technique requires domain knowledge.\n",
    "-   A Content-Based filtering model does not require any records about other users as the recommendations are to a particular user.\n",
    "-   The collaborative algorithm uses only user behavior for recommending items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5ac15e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35679e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings =  pd.read_csv('../Data/ratings.dat',sep='::',header=None,names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"], encoding=\"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f81e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e486eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb10db",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('../Data/movies.dat',sep='::',header=None,names=[\"MovieID\", \"Title\", \"Genres\"], encoding=\"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548e68f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d86252",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ff3f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('../Data/users.dat',sep='::',header=None,names=[\"UserID\", \"Gender\", \"Age\", \"Occupation\", \"Zip-code\"], encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbc2094",
   "metadata": {},
   "outputs": [],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33078a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "users.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5333c45",
   "metadata": {},
   "source": [
    "## Preprocessing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be48071",
   "metadata": {},
   "source": [
    "The Content-based recommendation method requires information about the item's features. Therefore we will use attributes of movies genres, overview and tagline to recommend movie\n",
    "\n",
    "As genere string has json type structure, we will strip the string and extract genres by using following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00c5410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_genres(text):\n",
    "    text=text.replace(\"[{'id': \",'')\n",
    "    text=text.replace(\", 'name': '\",' ')\n",
    "    text=text.lower()\n",
    "    text=text.replace(\", {'id': \",' ')\n",
    "    text=text.replace(\"'}\" ,'')\n",
    "    text=text.replace(\"'}]\" ,'')\n",
    "    text=text.replace(\"]\" ,'')\n",
    "    text=''.join([i for i in text if not i.isdigit()])\n",
    "    text=text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9125d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data from file\n",
    "df = pd.read_csv(\"../Data/movies_metadata.csv\")\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff18100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['genres'] = df['genres'].apply(clean_genres)\n",
    "\n",
    "df['tagline'] = df['tagline'].fillna('')\n",
    "df['movie_text'] = df['overview'] + df['tagline']+df['genres'] \n",
    "df['movie_text'] = df['movie_text'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88327d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifying text\n",
    "df['movie_text'][16212]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea65626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['movie_text'][1325]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df3c275",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['movie_text'][1326]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0079188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['movie_text'][1324]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49a986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['movie_text'][20922]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bf7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['movie_text'][1327]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79d206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer()\n",
    "tfidf_matrix = tf.fit_transform(df['movie_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2863088",
   "metadata": {},
   "source": [
    "The cosine similarity is the cosine of the angle between two vectors. It also has the identical inner product of the vectors if they were normalized to both have length one. Cosine similarity considers vector orientation, independent of vector magnitude.\n",
    "\n",
    "Computing cosine similarity between the movie text feature we created. Cosine similarity, or the cosine kernel will compute similarity as the normalized dot product of X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a809cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee97c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "titles = df['title']\n",
    "title_ids = pd.Series(df.index, index=df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d4de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_recommendations(title):\n",
    "    idx = title_ids[title]\n",
    "    cosine_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    #sorting scores in descending order\n",
    "    cosine_scores = sorted(cosine_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    #top 10 recommendations\n",
    "    cosine_scores = cosine_scores[1:10]\n",
    "    movie_indices = [i[0] for i in cosine_scores]\n",
    "    return titles.iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e9277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_content_recommendations('Star Trek: The Motion Picture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2f0dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_content_recommendations('Batman Forever') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844f112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_content_recommendations('The Hangover') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca86af88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9f3f0d",
   "metadata": {},
   "source": [
    "Use the below generated files to load model in server.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4414bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df, open('movies_df.pkl','wb'))\n",
    "pickle.dump(cosine_sim, open('similarity.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce4bba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255-project.ipynb              movies_df.pkl\r\n",
      "Collaborative filtering.ipynb  similarity.pkl\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee45fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = pickle.load(open('movies_df.pkl','rb'))\n",
    "sim = pickle.load(open('similarity.pkl','rb'))\n",
    "titles = movie_data['title']\n",
    "title_ids = pd.Series(movie_data.index, index=movie_data['title'])\n",
    "movie_poster_ids = movie_data['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c73e9aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Toy Story                          0\n",
       "Jumanji                            1\n",
       "Grumpier Old Men                   2\n",
       "Waiting to Exhale                  3\n",
       "Father of the Bride Part II        4\n",
       "                               ...  \n",
       "Subdue                         45461\n",
       "Century of Birthing            45462\n",
       "Betrayal                       45463\n",
       "Satan Triumphant               45464\n",
       "Queerama                       45465\n",
       "Length: 45466, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ffce9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_recommendations(title):\n",
    "    idx = title_ids[title]\n",
    "    cosine_scores = list(enumerate(sim[idx]))\n",
    "\n",
    "    #sorting scores in descending order\n",
    "    cosine_scores = sorted(cosine_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    #top 10 recommendations\n",
    "    cosine_scores = cosine_scores[1:10]\n",
    "    movie_indices = [i[0] for i in cosine_scores]\n",
    "    return movie_poster_ids.iloc[movie_indices],titles.iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d435d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbb64a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid,mdata = get_content_recommendations('The Hangover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22e89a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mid.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82e55a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = mdata.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1f80a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"28175\":\"252838\",\"2700\":\"11037\",\"25455\":\"292191\",\"24158\":\"276843\",\"2453\":\"16508\",\"39873\":\"238475\",\"37974\":\"343112\",\"6840\":\"6472\",\"15807\":\"23168\"}{\"28175\":\"The Wedding Ringer\",\"2700\":\"Iron Eagle\",\"25455\":\"Bachelor Night\",\"24158\":\"What We Did on Our Holiday\",\"2453\":\"Doug\\'s 1st Movie\",\"39873\":\"Best Night Ever\",\"37974\":\"Man Vs.\",\"6840\":\"Guarding Tess\",\"15807\":\"The Town\"}'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33714fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
